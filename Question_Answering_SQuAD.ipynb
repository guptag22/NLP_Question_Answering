{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering from Wikipedia articles\n",
    "\n",
    "Pre-requisites to run - \n",
    "Running this notebook requires certain packages to be pre-installed. \n",
    "* spacy\n",
    "* pandas\n",
    "* numpy\n",
    "* torch\n",
    "* sklearn\n",
    "\n",
    "Instructions to run - \n",
    "1. Download this Jupyter Notebook in a root folder\n",
    "2. Download and save the squad_train.json and squad_dev.json files for the SQuAD dataset in a folder called \"data\" and place this folder alongside the notebook in the root folder.\n",
    "3. Download the glove embeddings with 300 dimension for 6B tokens in the root folder.\n",
    "4. Run all cells in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "import time\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 300\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data:  48\n"
     ]
    }
   ],
   "source": [
    "## Load data json files and preprocess data in pandas dataframes\n",
    "\n",
    "squad_train_path = './data/squad_train.json'\n",
    "squad_dev_path = './data/squad_dev.json'\n",
    "glove_path = './glove.6B.300d.txt'\n",
    "glove = {}\n",
    "with open(squad_train_path, 'r', encoding='utf-8') as file:\n",
    "        train_json = json.load(file)\n",
    "file.close()\n",
    "with open(squad_dev_path, 'r', encoding='utf-8') as file:\n",
    "        dev_json = json.load(file)\n",
    "file.close()\n",
    "with open(glove_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        for embed in lines:\n",
    "            word = embed.split()[0]\n",
    "            emb = np.asarray(embed.split()[1:],dtype='float32')\n",
    "            glove[word] = emb\n",
    "file.close()\n",
    "print(\"Length of data: \", len(dev_json['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "textList = []\n",
    "def parse_json(json_obj: dict) -> list :\n",
    "    data = []\n",
    "    total_context = 0\n",
    "    for article in json_obj['data']:\n",
    "        for paragraph in article['paragraphs']:\n",
    "            ctx = \" \".join(paragraph['context'].split())\n",
    "            total_context += 1\n",
    "            textList.append(ctx)\n",
    "            for ques in paragraph['qas']:\n",
    "                ques_text = \" \".join(ques['question'].split())\n",
    "                textList.append(ques_text)\n",
    "                for ans in ques['answers']:\n",
    "                    ans_start_tag = ans['answer_start']\n",
    "                    ans_text = \" \".join(ans['text'].split())\n",
    "                    ans_end_tag = ans_start_tag + len(ans_text)\n",
    "                    new_example = {}\n",
    "                    new_example['context'] = ctx\n",
    "                    new_example['question'] = ques_text\n",
    "                    new_example['ques_id'] = ques['id']\n",
    "                    new_example['ans_text'] = ans_text\n",
    "                    new_example['ans_tags'] = [ans_start_tag,ans_end_tag]\n",
    "                    data.append(new_example)\n",
    "    print(total_context)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18896\n",
      "2067\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame(parse_json(train_json))\n",
    "val = pd.DataFrame(parse_json(dev_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118825"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textList = list(set(textList))\n",
    "len(textList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
    "    text = re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en',disable=['parser','tagger','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3989780\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for doc in nlp.pipe(textList,batch_size=50):\n",
    "    for token in doc:\n",
    "        tokens.append(token.text)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111082\n"
     ]
    }
   ],
   "source": [
    "vocab = Counter(tokens)\n",
    "vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
    "vocab.insert(0,'<unk>')\n",
    "vocab.insert(1,'<pad>')\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embed = np.zeros((len(vocab),EMBED_DIM))\n",
    "for i,word in enumerate(vocab):\n",
    "    if word in glove.keys():\n",
    "        word_embed[i] = glove[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111082, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxInVocab = {w:i for i,w in enumerate(vocab)}\n",
    "wordAtIdx = {i:w for w,i in idxInVocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each token in context and question text to corresponding index in vocab\n",
    "def map_text2idx(text):\n",
    "    indices = []\n",
    "    for token in nlp(text):\n",
    "        indices.append(idxInVocab[token.text])\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mapped_ctx'] = train.context.apply(map_text2idx)\n",
    "train['mapped_ques'] = train.question.apply(map_text2idx)\n",
    "val['mapped_ctx'] = val.context.apply(map_text2idx)\n",
    "val['mapped_ques'] = val.question.apply(map_text2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>ques_id</th>\n",
       "      <th>ans_text</th>\n",
       "      <th>ans_tags</th>\n",
       "      <th>mapped_ctx</th>\n",
       "      <th>mapped_ques</th>\n",
       "      <th>tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>[515, 541]</td>\n",
       "      <td>[60168, 3, 2, 209, 42, 10, 551, 822, 5, 97837,...</td>\n",
       "      <td>[401, 582, 25, 2, 3432, 856, 6288, 1063, 8, 85...</td>\n",
       "      <td>[102, 104]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>[188, 213]</td>\n",
       "      <td>[60168, 3, 2, 209, 42, 10, 551, 822, 5, 97837,...</td>\n",
       "      <td>[11, 12, 8, 1507, 4, 2, 1240, 1198, 5650, 2748...</td>\n",
       "      <td>[37, 41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>[279, 296]</td>\n",
       "      <td>[60168, 3, 2, 209, 42, 10, 551, 822, 5, 97837,...</td>\n",
       "      <td>[16, 6079, 4, 2, 10508, 2005, 36, 1240, 1198, ...</td>\n",
       "      <td>[57, 59]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>[381, 420]</td>\n",
       "      <td>[60168, 3, 2, 209, 42, 10, 551, 822, 5, 97837,...</td>\n",
       "      <td>[11, 12, 2, 23646, 36, 1240, 1198, 6]</td>\n",
       "      <td>[76, 82]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>[92, 126]</td>\n",
       "      <td>[60168, 3, 2, 209, 42, 10, 551, 822, 5, 97837,...</td>\n",
       "      <td>[11, 9367, 26, 454, 4, 2, 5650, 2748, 36, 1240...</td>\n",
       "      <td>[17, 23]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                    ques_id                                 ans_text  \\\n",
       "0  5733be284776f41900661182               Saint Bernadette Soubirous   \n",
       "1  5733be284776f4190066117f                a copper statue of Christ   \n",
       "2  5733be284776f41900661180                        the Main Building   \n",
       "3  5733be284776f41900661181  a Marian place of prayer and reflection   \n",
       "4  5733be284776f4190066117e       a golden statue of the Virgin Mary   \n",
       "\n",
       "     ans_tags                                         mapped_ctx  \\\n",
       "0  [515, 541]  [60168, 3, 2, 209, 42, 10, 551, 822, 5, 97837,...   \n",
       "1  [188, 213]  [60168, 3, 2, 209, 42, 10, 551, 822, 5, 97837,...   \n",
       "2  [279, 296]  [60168, 3, 2, 209, 42, 10, 551, 822, 5, 97837,...   \n",
       "3  [381, 420]  [60168, 3, 2, 209, 42, 10, 551, 822, 5, 97837,...   \n",
       "4   [92, 126]  [60168, 3, 2, 209, 42, 10, 551, 822, 5, 97837,...   \n",
       "\n",
       "                                         mapped_ques     tag_idx  \n",
       "0  [401, 582, 25, 2, 3432, 856, 6288, 1063, 8, 85...  [102, 104]  \n",
       "1  [11, 12, 8, 1507, 4, 2, 1240, 1198, 5650, 2748...    [37, 41]  \n",
       "2  [16, 6079, 4, 2, 10508, 2005, 36, 1240, 1198, ...    [57, 59]  \n",
       "3              [11, 12, 2, 23646, 36, 1240, 1198, 6]    [76, 82]  \n",
       "4  [11, 9367, 26, 454, 4, 2, 5650, 2748, 36, 1240...    [17, 23]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for examples which have wrong start and end tags\n",
    "## REFERENCE: https://github.com/kushalj001/pytorch-question-answering\n",
    "\n",
    "def test_indices(data):\n",
    "    start_tag_err = []\n",
    "    end_tag_err = []\n",
    "    assert_error = []\n",
    "    for idx, row in data.iterrows():\n",
    "        answer_tokens = [w.text for w in nlp(row['ans_text'])]\n",
    "        start_token = answer_tokens[0]\n",
    "        end_token = answer_tokens[-1]\n",
    "        context_span  = [(word.idx, word.idx + len(word.text)) for word in nlp(row['context'])]\n",
    "        starts, ends = zip(*context_span)\n",
    "        answer_start, answer_end = row['ans_tags']\n",
    "        try:\n",
    "            start_idx = starts.index(answer_start)\n",
    "        except:\n",
    "            start_tag_err.append(idx)\n",
    "        try:\n",
    "            end_idx  = ends.index(answer_end)\n",
    "        except:\n",
    "            end_tag_err.append(idx)\n",
    "        try:\n",
    "            assert wordAtIdx[row['mapped_ctx'][start_idx]] == answer_tokens[0]\n",
    "            assert wordAtIdx[row['mapped_ctx'][end_idx]] == answer_tokens[-1]\n",
    "        except:\n",
    "            assert_error.append(idx)\n",
    "    return start_tag_err, end_tag_err, assert_error\n",
    "\n",
    "def get_error_indices(data):\n",
    "    start_value_error, end_value_error, assert_error = test_indices(data)\n",
    "    err_idx = start_value_error + end_value_error + assert_error\n",
    "    err_idx = set(err_idx)\n",
    "    return err_idx\n",
    "\n",
    "def index_answer(row):\n",
    "    context_span = [(word.idx, word.idx + len(word.text)) for word in nlp(row.context)]\n",
    "    starts, ends = zip(*context_span)\n",
    "    \n",
    "    answer_start, answer_end = row.ans_tags\n",
    "    start_idx = starts.index(answer_start)\n",
    " \n",
    "    end_idx  = ends.index(answer_end)\n",
    "    \n",
    "    ans_tokens = [w.text for w in nlp(row.ans_text)]\n",
    "    ans_start = ans_tokens[0]\n",
    "    ans_end = ans_tokens[-1]\n",
    "    assert wordAtIdx[row.mapped_ctx[start_idx]] == ans_start\n",
    "    assert wordAtIdx[row.mapped_ctx[end_idx]] == ans_end\n",
    "    \n",
    "    return [start_idx, end_idx]\n",
    "\n",
    "train_err = get_error_indices(train)\n",
    "valid_err = get_error_indices(val)\n",
    "\n",
    "train.drop(train_err, inplace=True)\n",
    "val.drop(valid_err, inplace=True)\n",
    "\n",
    "train_tag_idx = train.apply(index_answer, axis=1)\n",
    "valid_tag_idx = val.apply(index_answer, axis=1)\n",
    "\n",
    "train['tag_idx'] = train_tag_idx\n",
    "val['tag_idx'] = valid_tag_idx\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>ques_id</th>\n",
       "      <th>ans_text</th>\n",
       "      <th>ans_tags</th>\n",
       "      <th>mapped_ctx</th>\n",
       "      <th>mapped_ques</th>\n",
       "      <th>tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>[177, 191]</td>\n",
       "      <td>[645, 743, 791, 13, 35, 113, 705, 361, 9, 1784...</td>\n",
       "      <td>[68, 3251, 296, 1270, 2, 11507, 36, 645, 743, ...</td>\n",
       "      <td>[33, 34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>[177, 191]</td>\n",
       "      <td>[645, 743, 791, 13, 35, 113, 705, 361, 9, 1784...</td>\n",
       "      <td>[68, 3251, 296, 1270, 2, 11507, 36, 645, 743, ...</td>\n",
       "      <td>[33, 34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>[177, 191]</td>\n",
       "      <td>[645, 743, 791, 13, 35, 113, 705, 361, 9, 1784...</td>\n",
       "      <td>[68, 3251, 296, 1270, 2, 11507, 36, 645, 743, ...</td>\n",
       "      <td>[33, 34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>[249, 266]</td>\n",
       "      <td>[645, 743, 791, 13, 35, 113, 705, 361, 9, 1784...</td>\n",
       "      <td>[68, 3251, 296, 1270, 2, 9450, 36, 645, 743, 7...</td>\n",
       "      <td>[44, 45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>[249, 266]</td>\n",
       "      <td>[645, 743, 791, 13, 35, 113, 705, 361, 9, 1784...</td>\n",
       "      <td>[68, 3251, 296, 1270, 2, 9450, 36, 645, 743, 7...</td>\n",
       "      <td>[44, 45]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Super Bowl 50 was an American football game to...   \n",
       "1  Super Bowl 50 was an American football game to...   \n",
       "2  Super Bowl 50 was an American football game to...   \n",
       "3  Super Bowl 50 was an American football game to...   \n",
       "4  Super Bowl 50 was an American football game to...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Which NFL team represented the AFC at Super Bo...   \n",
       "1  Which NFL team represented the AFC at Super Bo...   \n",
       "2  Which NFL team represented the AFC at Super Bo...   \n",
       "3  Which NFL team represented the NFC at Super Bo...   \n",
       "4  Which NFL team represented the NFC at Super Bo...   \n",
       "\n",
       "                    ques_id           ans_text    ans_tags  \\\n",
       "0  56be4db0acb8001400a502ec     Denver Broncos  [177, 191]   \n",
       "1  56be4db0acb8001400a502ec     Denver Broncos  [177, 191]   \n",
       "2  56be4db0acb8001400a502ec     Denver Broncos  [177, 191]   \n",
       "3  56be4db0acb8001400a502ed  Carolina Panthers  [249, 266]   \n",
       "4  56be4db0acb8001400a502ed  Carolina Panthers  [249, 266]   \n",
       "\n",
       "                                          mapped_ctx  \\\n",
       "0  [645, 743, 791, 13, 35, 113, 705, 361, 9, 1784...   \n",
       "1  [645, 743, 791, 13, 35, 113, 705, 361, 9, 1784...   \n",
       "2  [645, 743, 791, 13, 35, 113, 705, 361, 9, 1784...   \n",
       "3  [645, 743, 791, 13, 35, 113, 705, 361, 9, 1784...   \n",
       "4  [645, 743, 791, 13, 35, 113, 705, 361, 9, 1784...   \n",
       "\n",
       "                                         mapped_ques   tag_idx  \n",
       "0  [68, 3251, 296, 1270, 2, 11507, 36, 645, 743, ...  [33, 34]  \n",
       "1  [68, 3251, 296, 1270, 2, 11507, 36, 645, 743, ...  [33, 34]  \n",
       "2  [68, 3251, 296, 1270, 2, 11507, 36, 645, 743, ...  [33, 34]  \n",
       "3  [68, 3251, 296, 1270, 2, 9450, 36, 645, 743, 7...  [44, 45]  \n",
       "4  [68, 3251, 296, 1270, 2, 9450, 36, 645, 743, 7...  [44, 45]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a dataloader\n",
    "\n",
    "class dataloader:\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        i = 0\n",
    "        self.data = []\n",
    "        while i+batch_size < len(data):\n",
    "            self.data.append(data[i:i+batch_size])\n",
    "            i = i+batch_size\n",
    "        if i<len(data):\n",
    "            self.data.append(data[i:])\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __iter__(self):\n",
    "        for batch in self.data:\n",
    "            ctx_pad_len = max([len(ctx) for ctx in batch.mapped_ctx])\n",
    "            ques_pad_len = max([len(ques) for ques in batch.mapped_ques])\n",
    "            pad_ques = torch.LongTensor(len(batch),ques_pad_len).fill_(1)\n",
    "            pad_ctx = torch.LongTensor(len(batch), ctx_pad_len).fill_(1)\n",
    "            for i,ctx in enumerate(batch.mapped_ctx):\n",
    "                pad_ctx[i,:len(ctx)] = torch.LongTensor(ctx)\n",
    "            for i,ques in enumerate(batch.mapped_ques):\n",
    "                pad_ques[i,:len(ques)] = torch.LongTensor(ques)\n",
    "            pad_ctx_mask = torch.eq(pad_ctx,1)\n",
    "            pad_ques_mask = torch.eq(pad_ques,1)\n",
    "            yield (pad_ctx,\n",
    "                   pad_ctx_mask,\n",
    "                   pad_ques,\n",
    "                   pad_ques_mask,\n",
    "                   torch.LongTensor(list(batch.tag_idx)),\n",
    "                   list(batch.context),\n",
    "                   list(batch.ans_text),\n",
    "                   list(batch.ques_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReaderModel(nn.Module):\n",
    "    def __init__(self,hidden_dim,embed_dim,num_lstm,dropout):\n",
    "        super().__init__()\n",
    "        self.num_lstm = num_lstm\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dropout = dropout\n",
    "        self.encoding_dim = hidden_dim*num_lstm*2\n",
    "        def tune_embedding(grad, words=1000):\n",
    "            grad[words:] = 0\n",
    "            return grad\n",
    "        self.dropout_layer = nn.Dropout(self.dropout)\n",
    "        self.embed_layer = nn.Embedding.from_pretrained(torch.FloatTensor(word_embed).to(device),freeze=False)\n",
    "        self.embed_layer.weight.register_hook(tune_embedding)\n",
    "        self.f_align_layer = F_align(self.embed_dim)\n",
    "        self.ques_encod_layer = Ques_Encode(self.encoding_dim)\n",
    "        self.ctx_rnn = RNNLayer(self.embed_dim*2,self.hidden_dim,self.num_lstm,self.dropout)\n",
    "        self.ques_rnn = RNNLayer(self.embed_dim,self.hidden_dim,self.num_lstm,self.dropout)\n",
    "        self.start_classifier_layer = Classifier(self.encoding_dim)\n",
    "        self.end_classifier_layer = Classifier(self.encoding_dim)\n",
    "        \n",
    "    def forward(self,ctx,ctx_mask,ques,ques_mask,flag):\n",
    "        ctx_embed = self.embed_layer(ctx)\n",
    "#         if flag:\n",
    "#             print(f\"got ctx_embed {ctx_embed.shape}\")\n",
    "        ques_embed = self.embed_layer(ques)\n",
    "#         if flag:\n",
    "#             print(f\"got ques_embed {ques_embed.shape}\")\n",
    "        f_align = self.f_align_layer(ctx_embed,ques_embed,ques_mask)\n",
    "#         if flag:\n",
    "#             print(f\"got f_align {f_align.shape}\")\n",
    "        ctx_features = torch.cat([ctx_embed,f_align],dim=2)\n",
    "#         if flag:\n",
    "#             print(f\"got ctx_features {ctx_features.shape}\")\n",
    "        ctx_encoding = self.ctx_rnn(ctx_features)\n",
    "#         if flag:\n",
    "#             print(f\"got ctx_encoding {ctx_encoding.shape}\")\n",
    "        ques_features = self.ques_rnn(ques_embed)\n",
    "#         if flag:\n",
    "#             print(f\"got ques_features {ques_features.shape}\")\n",
    "        ques_features_bi = self.ques_encod_layer(ques_features,ques_mask)\n",
    "#         if flag:\n",
    "#             print(f\"got ques_features_bi {ques_features_bi.shape}\")\n",
    "        ques_encoding = ques_features_bi.unsqueeze(1).bmm(ques_features).squeeze(1)\n",
    "#         if flag:\n",
    "#             print(f\"got ques_encoding {ques_encoding.shape}\")\n",
    "        start_class = self.start_classifier_layer(ctx_encoding,ques_encoding,ctx_mask)\n",
    "#         if flag:\n",
    "#             print(f\"got start_class {start_class.shape}\")\n",
    "        end_class = self.end_classifier_layer(ctx_encoding,ques_encoding,ctx_mask)\n",
    "#         if flag:\n",
    "#             print(f\"got end_class {end_class.shape}\")\n",
    "        return start_class,end_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F_align(nn.Module):\n",
    "    def __init__(self,embed_dim):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(embed_dim,embed_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,ctx,ques,mask):\n",
    "        alpha_ctx = self.relu(self.dense(ctx))\n",
    "        alpha_ques = self.relu(self.dense(ques)).permute(0,2,1)\n",
    "        aij = torch.bmm(alpha_ctx,alpha_ques)\n",
    "        mask_reshaped = mask.unsqueeze(1).expand(aij.size())\n",
    "        aij = aij.masked_fill(mask_reshaped == 1, -float('inf')).view(-1, ques.shape[1])\n",
    "        align_weights = F.softmax(aij,dim=1).view(-1,ctx.shape[1],ques.shape[1])\n",
    "        return torch.bmm(align_weights,ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ques_Encode(nn.Module):\n",
    "    def __init__(self,encoding_dim):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(encoding_dim,1)\n",
    "    def forward(self,features,mask):\n",
    "        bs,features_len,feature_dim = features.shape\n",
    "        bj = self.dense(features.view(-1,feature_dim)).view(bs,features_len)\n",
    "        bj = bj.masked_fill(mask == 1, -float('inf'))\n",
    "        return F.softmax(bj,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLayer(nn.Module):\n",
    "    def __init__(self,embed_dim,hidden_dim,num_lstm,dropout):\n",
    "        super().__init__()\n",
    "        self.input_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.nlayers = num_lstm\n",
    "        self.dropout = dropout\n",
    "        self.blstm = nn.ModuleList()\n",
    "        self.blstm.append(nn.LSTM(self.input_dim,self.hidden_dim,batch_first=True,bidirectional=True))\n",
    "        n = 1\n",
    "        while (n<num_lstm):\n",
    "            self.blstm.append(nn.LSTM(self.hidden_dim*2,self.hidden_dim,batch_first=True,bidirectional=True))\n",
    "            n += 1\n",
    "    def forward(self,features):\n",
    "        first_layer_out, (h,c) = self.blstm[0](features)\n",
    "        all_out = [first_layer_out]\n",
    "        i = 1\n",
    "        while i<self.nlayers :\n",
    "            out,(h,c) = self.blstm[i](all_out[-1])\n",
    "            all_out.append(out)\n",
    "            i += 1\n",
    "        all_out = torch.cat(all_out,dim=2)\n",
    "        return F.dropout(all_out,p=self.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self,encoding_dim):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(encoding_dim,encoding_dim)\n",
    "    def forward(self,ctx,ques,mask):\n",
    "        q = self.dense(ques)\n",
    "        class_score = (ctx.bmm(q.unsqueeze(2))).squeeze(2)\n",
    "        class_score = class_score.masked_fill(mask == 1, -float('inf'))\n",
    "        return class_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.3\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LSTM = 3\n",
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ReaderModel(HIDDEN_DIM,EMBED_DIM,NUM_LSTM,DROPOUT)\n",
    "opt = torch.optim.Adamax(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model,data):\n",
    "    model.train()\n",
    "    batch_ind = 0\n",
    "    total_loss = 0\n",
    "    for batch in data:\n",
    "        flag = False\n",
    "        if batch_ind%500 == 0:\n",
    "            print(f\"Batch {batch_ind}\")\n",
    "            flag = True\n",
    "        batch_ind +=1\n",
    "        ctx,ctx_mask,ques,ques_mask,tags,ctx_text,ans_text,ques_id = batch\n",
    "        opt.zero_grad()\n",
    "        pred = model(ctx,ctx_mask,ques,ques_mask,flag)\n",
    "        start_pred,end_pred = pred\n",
    "#         if flag:\n",
    "#             print(f\" got preds {start_pred.shape} {end_pred.shape}\")\n",
    "        start_tags = tags[:,0]\n",
    "        end_tags = tags[:,1]\n",
    "        start_pred_loss = F.cross_entropy(start_pred,start_tags)\n",
    "        end_pred_loss = F.cross_entropy(end_pred,end_tags)\n",
    "        batch_loss = start_pred_loss + end_pred_loss\n",
    "        batch_loss.backward()\n",
    "#         if flag:\n",
    "#             print(f\"batch loss {batch_loss}\")\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "        opt.step()\n",
    "        total_loss += batch_loss.item()\n",
    "    return total_loss/batch_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model,data):\n",
    "    model.eval()\n",
    "    batch_ind = 0\n",
    "    total_loss = 0\n",
    "    predictions = {}\n",
    "    for batch in data:\n",
    "        flag = False\n",
    "        if batch_ind%500 == 0:\n",
    "            print(f\"Batch {batch_ind}\")\n",
    "            flag = True\n",
    "        batch_ind +=1\n",
    "        ctx,ctx_mask,ques,ques_mask,tags,ctx_text,ans_text,ques_id = batch\n",
    "        bs, len_c = ctx.shape\n",
    "        lsoftmax = nn.LogSoftmax(dim=1)\n",
    "        with torch.no_grad():\n",
    "            start_pred,end_pred = model(ctx,ctx_mask,ques,ques_mask,flag)\n",
    "            start_tags = tags[:,0]\n",
    "            end_tags = tags[:,1]\n",
    "            start_pred_loss = F.cross_entropy(start_pred,start_tags)\n",
    "            end_pred_loss = F.cross_entropy(end_pred,end_tags)\n",
    "            batch_loss = start_pred_loss + end_pred_loss\n",
    "            total_loss += batch_loss.item()\n",
    "            # Get predictions\n",
    "            mask = torch.ones(len_c, len_c) * float('-inf')\n",
    "            mask = mask.tril(-1).unsqueeze(0).expand(bs, -1, -1)\n",
    "            score = (lsoftmax(start_pred).unsqueeze(2) + lsoftmax(end_pred).unsqueeze(1)) + mask\n",
    "            score, s_idx = score.max(dim=1)\n",
    "            score, e_idx = score.max(dim=1)\n",
    "            s_idx = torch.gather(s_idx, 1, e_idx.view(-1, 1)).squeeze()\n",
    "            for i in range(bs):\n",
    "                q_id = ques_id[i]\n",
    "                pred = ctx[i][s_idx[i]:e_idx[i]+1]\n",
    "                pred = ' '.join([wordAtIdx[idx.item()] for idx in pred])\n",
    "                predictions[q_id] = pred\n",
    "                        \n",
    "    f1 = 0\n",
    "    total = 0\n",
    "    ground_truths = {}\n",
    "    for it,row in val.iterrows():\n",
    "        q_id = row['ques_id']\n",
    "        if q_id in predictions:\n",
    "            total +=1\n",
    "            if q_id not in ground_truths:\n",
    "                ground_truths[q_id] = [row['ans_text']]\n",
    "            else:\n",
    "                ground_truths[q_id].append(row['ans_text'])\n",
    "    for q_id in predictions:\n",
    "        scores = []\n",
    "        for gt in ground_truths[q_id]:\n",
    "            pred = process_text(predictions[q_id]).split()\n",
    "            ans = process_text(gt).split()\n",
    "            num_common_words = sum((Counter(pred) & Counter(ans)).values())\n",
    "            if num_common_words ==0:\n",
    "                score = 0\n",
    "            else:\n",
    "                p = num_common_words / len(pred)\n",
    "                r = num_common_words / len(ans)\n",
    "                score = (2 * p * r) / (p + r)\n",
    "            scores.append(score)\n",
    "        f1_score = max(scores)\n",
    "        f1 += f1_score\n",
    "    return total_loss/batch_ind, f1*100/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "starting training\n",
      "Batch 0\n",
      "Batch 500\n",
      "Batch 1000\n",
      "Batch 1500\n",
      "Batch 2000\n",
      "Batch 2500\n",
      "starting validation\n",
      "Batch 0\n",
      "Batch 500\n",
      "Batch 1000\n",
      "F1 score : 15.72443297317382\n",
      "----------- End of epoch  1\n",
      "EPOCH 2\n",
      "starting training\n",
      "Batch 0\n",
      "Batch 500\n",
      "Batch 1000\n",
      "Batch 1500\n",
      "Batch 2000\n",
      "Batch 2500\n",
      "starting validation\n",
      "Batch 0\n",
      "Batch 500\n",
      "Batch 1000\n",
      "F1 score : 17.55806947400931\n",
      "----------- End of epoch  2\n",
      "EPOCH 3\n",
      "starting training\n",
      "Batch 0\n",
      "Batch 500\n",
      "Batch 1000\n",
      "Batch 1500\n",
      "Batch 2000\n",
      "Batch 2500\n",
      "starting validation\n",
      "Batch 0\n",
      "Batch 500\n",
      "Batch 1000\n",
      "F1 score : 18.15879685181556\n",
      "----------- End of epoch  3\n",
      "EPOCH 4\n",
      "starting training\n",
      "Batch 0\n",
      "Batch 500\n",
      "Batch 1000\n",
      "Batch 1500\n",
      "Batch 2000\n",
      "Batch 2500\n",
      "starting validation\n",
      "Batch 0\n",
      "Batch 500\n",
      "Batch 1000\n",
      "F1 score : 18.24309980073122\n",
      "----------- End of epoch  4\n"
     ]
    }
   ],
   "source": [
    "train_data = dataloader(train,BATCH_SIZE)\n",
    "val_data = dataloader(val,BATCH_SIZE)\n",
    "for i in range(EPOCHS) :\n",
    "    print(f\"EPOCH {i+1}\")\n",
    "    start = time.time()\n",
    "    print(\"starting training\")\n",
    "    train_loss = training(model,train_data)\n",
    "    print(\"starting validation\")\n",
    "    val_loss, f1 = validation(model,val_data)\n",
    "    end = time.time()\n",
    "    total_time = end-start\n",
    "    minutes = int(total_time/60)\n",
    "    secs = int(total_time-(minutes*60))\n",
    "#     print(f\"Time spent {minutes} min {secs} sec.\")\n",
    "    print(f\"F1 score : {f1}\")\n",
    "    print(\"----------- End of epoch \",i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
